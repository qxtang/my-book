<!DOCTYPE html>
<html lang="zh-cn">
  <head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>My Book - readme</title>

  <link rel="stylesheet" href="/my-book/resource/lib/github-markdown.min.css" />
  <link rel="stylesheet" href="/my-book/resource/style.css" />
  <link rel="stylesheet" href="/my-book/resource/lib/highlight/default.min.css" />
  <script src="/my-book/resource/lib/highlight/highlight.min.js"></script>
  <script src="/my-book/resource/lib/jquery.min.js"></script>
  <script src="//unpkg.com/viewerjs@1.10.4/dist/viewer.min.js"></script>
  <script src="//unpkg.com/jquery-viewer@1.0.1/dist/jquery-viewer.min.js"></script>
  <link rel="stylesheet" href="//unpkg.com/viewerjs@1.10.4/dist/viewer.min.css" />

  <link rel="manifest" href="/my-book/manifest.json" />
  <link rel="shortcut icon" type="image/x-icon" href="/my-book/resource/favicon.ico" />
  <link rel="bookmark" type="image/x-icon" href="/my-book/resource/favicon.ico" />
  <link rel="apple-touch-icon" href="/my-book/resource/favicon.ico" />

  <!-- 编译时间：3/27/2022, 3:51:00 PM -->

  <script>
    window.root = '/my-book';
    hljs.highlightAll();
  </script>

  <script src="/my-book/resource/script.js"></script>
</head>

  <body>
    <div class="content markdown-body"><h1>EventStream</h1>
<p>&lt;img src=https://secure.travis-ci.org/dominictarr/event-stream.png?branch=master&gt;</p>
<p>[<img src="http://ci.testling.com/dominictarr/event-stream.png" alt="browser status">]
(http://ci.testling.com/dominictarr/event-stream)</p>
<p><a href="http://nodejs.org/api/stream.html" title="Stream">Streams</a> are node's best and most misunderstood idea, and
<em><em>EventStream</em></em> is a toolkit to make creating and working with streams <em>easy</em>.</p>
<p>Normally, streams are only used for IO,<br>
but in event stream we send all kinds of objects down the pipe.<br>
If your application's <em>input</em> and <em>output</em> are streams,<br>
shouldn't the <em>throughput</em> be a stream too?</p>
<p>The <em>EventStream</em> functions resemble the array functions,<br>
because Streams are like Arrays, but laid out in time, rather than in memory.</p>
<p><em>All the <code>event-stream</code> functions return instances of <code>Stream</code></em>.</p>
<p><code>event-stream</code> creates
<a href="https://github.com/joyent/node/blob/v0.8/doc/api/stream.markdown">0.8 streams</a>
, which are compatible with <a href="http://nodejs.org/api/stream.html" title="Stream">0.10 streams</a>.</p>
<blockquote>
<p>NOTE: I shall use the term <em>&quot;through stream&quot;</em> to refer to a stream that is writable <em>and</em> readable.</p>
</blockquote>
<h3><a href="https://github.com/dominictarr/event-stream/blob/master/examples/pretty.js">simple example</a>:</h3>
<pre><code class="language-js">
//pretty.js

if(!module.parent) {
  var es = require('event-stream')
  var inspect = require('util').inspect

  process.stdin                        //connect streams together with `pipe`
    .pipe(es.split())                  //split stream to break on newlines
    .pipe(es.map(function (data, cb) { //turn this async function into a stream
      cb(null
        , inspect(JSON.parse(data)))   //render it nicely
    }))
    .pipe(process.stdout)              // pipe it to stdout !
}
</code></pre>
<p>run it ...</p>
<pre><code class="language-bash">curl -sS registry.npmjs.org/event-stream | node pretty.js
</code></pre>
<p><a href="http://nodejs.org/api/stream.html">node Stream documentation</a></p>
<h2>through (write?, end?)</h2>
<p>Re-emits data synchronously. Easy way to create synchronous through streams.
Pass in optional <code>write</code> and <code>end</code> methods. They will be called in the
context of the stream. Use <code>this.pause()</code> and <code>this.resume()</code> to manage flow.
Check <code>this.paused</code> to see current flow state. (write always returns <code>!this.paused</code>)</p>
<p>this function is the basis for most of the synchronous streams in <code>event-stream</code>.</p>
<pre><code class="language-js">
es.through(function write(data) {
    this.emit('data', data)
    //this.pause() 
  },
  function end () { //optional
    this.emit('end')
  })

</code></pre>
<h2>map (asyncFunction)</h2>
<p>Create a through stream from an asynchronous function.</p>
<pre><code class="language-js">var es = require('event-stream')

es.map(function (data, callback) {
  //transform data
  // ...
  callback(null, data)
})

</code></pre>
<p>Each map MUST call the callback. It may callback with data, with an error or with no arguments,</p>
<ul>
<li>
<p><code>callback()</code> drop this data.<br>
this makes the map work like <code>filter</code>,<br>
note:<code>callback(null,null)</code> is not the same, and will emit <code>null</code></p>
</li>
<li>
<p><code>callback(null, newData)</code> turn data into newData</p>
</li>
<li>
<p><code>callback(error)</code> emit an error for this item.</p>
</li>
</ul>
<blockquote>
<p>Note: if a callback is not called, <code>map</code> will think that it is still being processed,<br>
every call must be answered or the stream will not know when to end.</p>
<p>Also, if the callback is called more than once, every call but the first will be ignored.</p>
</blockquote>
<h2>mapSync (syncFunction)</h2>
<p>Same as <code>map</code>, but the callback is called synchronously. Based on <code>es.through</code></p>
<h2>split (matcher)</h2>
<p>Break up a stream and reassemble it so that each line is a chunk. matcher may be a <code>String</code>, or a <code>RegExp</code></p>
<p>Example, read every line in a file ...</p>
<pre><code class="language-js">fs.createReadStream(file, {flags: 'r'})
  .pipe(es.split())
  .pipe(es.map(function (line, cb) {
    //do something with the line 
    cb(null, line)
  }))
</code></pre>
<p><code>split</code> takes the same arguments as <code>string.split</code> except it defaults to '\n' instead of ',', and the optional <code>limit</code> parameter is ignored.
<a href="https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/String/split">String#split</a></p>
<h2>join (separator)</h2>
<p>Create a through stream that emits <code>separator</code> between each chunk, just like Array#join.</p>
<p>(for legacy reasons, if you pass a callback instead of a string, join is a synonym for <code>es.wait</code>)</p>
<h2>merge (stream1,...,streamN) or merge (streamArray)</h2>
<blockquote>
<p>concat → merge</p>
</blockquote>
<p>Merges streams into one and returns it.
Incoming data will be emitted as soon it comes into - no ordering will be applied (for example: <code>data1 data1 data2 data1 data2</code> - where <code>data1</code> and <code>data2</code> is data from two streams).
Counts how many streams were passed to it and emits end only when all streams emitted end.</p>
<pre><code class="language-js">es.merge(
  process.stdout,
  process.stderr
).pipe(fs.createWriteStream('output.log'));
</code></pre>
<p>It can also take an Array of streams as input like this:</p>
<pre><code class="language-js">es.merge([
  fs.createReadStream('input1.txt'),
  fs.createReadStream('input2.txt')
]).pipe(fs.createWriteStream('output.log'));
</code></pre>
<h2>replace (from, to)</h2>
<p>Replace all occurrences of <code>from</code> with <code>to</code>. <code>from</code> may be a <code>String</code> or a <code>RegExp</code>.<br>
Works just like <code>string.split(from).join(to)</code>, but streaming.</p>
<h2>parse</h2>
<p>Convenience function for parsing JSON chunks. For newline separated JSON,
use with <code>es.split</code>.  By default it logs parsing errors by <code>console.error</code>;
for another behaviour, transforms created by <code>es.parse({error: true})</code> will
emit error events for exceptions thrown from <code>JSON.parse</code>, unmodified.</p>
<pre><code class="language-js">fs.createReadStream(filename)
  .pipe(es.split()) //defaults to lines.
  .pipe(es.parse())
</code></pre>
<h2>stringify</h2>
<p>convert javascript objects into lines of text. The text will have whitespace escaped and have a <code>\n</code> appended, so it will be compatible with <code>es.parse</code></p>
<pre><code class="language-js">objectStream
  .pipe(es.stringify())
  .pipe(fs.createWriteStream(filename))
</code></pre>
<h2>readable (asyncFunction)</h2>
<p>create a readable stream (that respects pause) from an async function.<br>
while the stream is not paused,<br>
the function will be polled with <code>(count, callback)</code>,<br>
and <code>this</code>  will be the readable stream.</p>
<pre><code class="language-js">
es.readable(function (count, callback) {
  if(streamHasEnded)
    return this.emit('end')
  
  //...
  
  this.emit('data', data) //use this way to emit multiple chunks per call.
      
  callback() // you MUST always call the callback eventually.
             // the function will not be called again until you do this.
})
</code></pre>
<p>you can also pass the data and the error to the callback.<br>
you may only call the callback once.<br>
calling the same callback more than once will have no effect.</p>
<h2>readArray (array)</h2>
<p>Create a readable stream from an Array.</p>
<p>Just emit each item as a data event, respecting <code>pause</code> and <code>resume</code>.</p>
<pre><code class="language-js">  var es = require('event-stream')
    , reader = es.readArray([1,2,3])

  reader.pipe(...)
</code></pre>
<p>If you want the stream behave like a 0.10 stream you will need to wrap it using <a href="http://nodejs.org/api/stream.html#stream_readable_wrap_stream"><code>Readable.wrap()</code></a> function. Example:</p>
<pre><code class="language-js">	var s = new stream.Readable({objectMode: true}).wrap(es.readArray([1,2,3]));
</code></pre>
<h2>writeArray (callback)</h2>
<p>create a writeable stream from a callback,<br>
all <code>data</code> events are stored in an array, which is passed to the callback when the stream ends.</p>
<pre><code class="language-js">  var es = require('event-stream')
    , reader = es.readArray([1, 2, 3])
    , writer = es.writeArray(function (err, array){
      //array deepEqual [1, 2, 3]
    })

  reader.pipe(writer)
</code></pre>
<h2>pause  ()</h2>
<p>A stream that buffers all chunks when paused.</p>
<pre><code class="language-js">  var ps = es.pause()
  ps.pause() //buffer the stream, also do not allow 'end' 
  ps.resume() //allow chunks through
</code></pre>
<h2>duplex (writeStream, readStream)</h2>
<p>Takes a writable stream and a readable stream and makes them appear as a readable writable stream.</p>
<p>It is assumed that the two streams are connected to each other in some way.</p>
<p>(This is used by <code>pipeline</code> and <code>child</code>.)</p>
<pre><code class="language-js">  var grep = cp.exec('grep Stream')

  es.duplex(grep.stdin, grep.stdout)
</code></pre>
<h2>child (child_process)</h2>
<p>Create a through stream from a child process ...</p>
<pre><code class="language-js">  var cp = require('child_process')

  es.child(cp.exec('grep Stream')) // a through stream

</code></pre>
<h2>wait (callback)</h2>
<p>waits for stream to emit 'end'.
joins chunks of a stream into a single string or buffer.
takes an optional callback, which will be passed the
complete string/buffer when it receives the 'end' event.</p>
<p>also, emits a single 'data' event.</p>
<pre><code class="language-js">
readStream.pipe(es.wait(function (err, body) {
  // have complete text here.
}))

</code></pre>
<h1>Other Stream Modules</h1>
<p>These modules are not included as a part of <em>EventStream</em> but may be
useful when working with streams.</p>
<h2><a href="https://github.com/parshap/node-stream-reduce">reduce (syncFunction, initial)</a></h2>
<p>Like <code>Array.prototype.reduce</code> but for streams. Given a sync reduce
function and an initial value it will return a through stream that emits
a single data event with the reduced value once the input stream ends.</p>
<pre><code class="language-js">var reduce = require(&quot;stream-reduce&quot;);
process.stdin.pipe(reduce(function(acc, data) {
  return acc + data.length;
}, 0)).on(&quot;data&quot;, function(length) {
  console.log(&quot;stdin size:&quot;, length);
});
</code></pre>
</div>
  </body>
</html>
